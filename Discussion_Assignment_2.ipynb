{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Gillian McGovern"
      ],
      "metadata": {
        "id": "XvaKbk2bYfZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some points from *Music Recommendations at Scale with Spark* I found interesting are:\n",
        "\n",
        "\n",
        "\n",
        "*   Pandora uses music experts to manually tag attributes. Although this is a lot of manual work, I found this very fascinating. I am curious how these recommendations compare to other music recommendations. Can you get the same data from web scraping?\n",
        "*   Spotify uses collaborative filtering using binary, implicit matrix factorization such as if a user streams a song, to infer ratings. ALS matrix factorization can still use this type of data to create meaningful rating predictions. Instead of treating songs that have been listened to just as 1, Spotify uses total streams as weights to give more weight to songs that have been listened to hundreds of times. For this method, all the 0s are not included, only the songs that the listener has listened to are factored in. This diminishes the amount of data required.\n",
        "*   When comparing to Hadoop, Spotify found Spark useful since it allows loading data into memory instead of rereading from disk every iteration. Spark can keep performing iterations. There were many attempts to set up Spark for their recommender system. A lot of the attempts involved balancing how to distribute the data to workers, and the overall time. The first attempt involving broadcasting everything did not work since this involved unnecessary shuffiling of the data and never caching anything. A full copy of the data was sent to every worker which is also unnecessary and takes up resources. The second attempt was a full gridify solution similar to Hadoop. This helped with ratings shuffling and memory. This still had issues of shuffling when grouping by user. The third attempt, which had the fastest running time of 1.5 hours, was half gridify. This solved the additional shuffling/aggregation issues, but this method could potentially need a full copy of each item vector for each partition. This also could require more local memory.\n",
        "*   Overall, this video showed how useful Spark can be, and how important testing and trying out parameters is when scaling recommender systems that need to handle massive amounts of data."
      ],
      "metadata": {
        "id": "ui-xbDEVYiKU"
      }
    }
  ]
}